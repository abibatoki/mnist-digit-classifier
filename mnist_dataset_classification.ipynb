{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5f6d34-92a6-49b2-a1e6-39734130aeff",
   "metadata": {},
   "source": [
    "**Import the relevant packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6263adf-c6a7-4e65-a827-5969ef7fa9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\udemycourse\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce52963-9f3a-46ce-b4d7-14ee5f7e7b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9.2\n"
     ]
    }
   ],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fba57b-c885-48a6-9cdd-3e95a35b1104",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a97509e-5876-4e51-a7a3-1adef29c1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cfd43-0077-493a-b5a7-423e2027307c",
   "metadata": {},
   "source": [
    "**Extract train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eeed2e1-051f-4275-a7f9-235b9e0fd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474fad22-365b-4f6d-ba35-2fa959e548f1",
   "metadata": {},
   "source": [
    "**take an arbitrary percentage of the train data to serve as validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "309057ba-0a70-4f4a-8cfe-9f10cf1bf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take 10% of the training data\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a376c6a-5168-44d2-b06a-52c7ece0210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store test samples in a dedicated variable\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50684202-d754-47d6-a19a-e0a89b907b03",
   "metadata": {},
   "source": [
    "**Scale the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99d38a07-d466-40fe-aabd-a640e8e039b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data to make the result more numerically stable (i.e have inputs between 0 & 1)\n",
    "#define a fxn that will scale the inputs\n",
    "#as a precaution, make sure all values are floats\n",
    "#you can scale your data as you see fit but ensure the function take image and label and returns image and label\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.  #dot here means we want the result to be a float\n",
    "    return image, label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "140321c4-95fe-4231-9747-3db9ee904a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will scale the whole dataset and store it in the new variable\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c898b320-3722-4be3-8dd9-75f31e08b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale and batch the test data\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd8b70-df7d-4521-b067-41bf897b6fc3",
   "metadata": {},
   "source": [
    "**Shuffle the data and create the validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c742dcb7-5c46-4fbb-86ae-b5851f6a88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling is basically keeping the same information in a different order\n",
    "#it should be as randomly spread as possible so the batching works as intended\n",
    "\n",
    "BUFFER_SIZE = 10000 #useful when dealing with enormous dataset, where we can't shuffle all data at once\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d777228e-c419-4403-a878-eaa1b5159c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the train and validation datasets\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a239a5b9-d386-4fbb-a68d-575b72acea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train data by extracting all elements but the first 'x' validation samples\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79ea2ee3-0f71-4f16-b7d5-07915fab9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are using mini-batch gradient descent to train our model\n",
    "#set the batch size and prepare our data for batching\n",
    "#batch size = 1 = SGD\n",
    "#batch size = nos of samples = single batch GD\n",
    "#1 < batch size < nos of samples = mini=batch GD\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cbdac74-82c5-47f7-9f60-bc2928bc5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs, validation_targets = next(iter(validation_data)) #this will make the dataset iterable but will not load any data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88edcf68-e20f-4b39-93e3-36a27742aebb",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9a320-3fbf-4f0a-99b1-209612d054eb",
   "metadata": {},
   "source": [
    "**Outline the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d989e46-ee1d-424d-a6b3-281a9ffe0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 200 #the underlying assumption is that all hidden layers are of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd8798e4-cd07-48ce-84b4-eae381f76930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the actual model\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbf897-f464-4710-9b0a-455822011fb6",
   "metadata": {},
   "source": [
    "**Choose the optimizer and loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cef7fff-ef73-4e59-a396-c41c7b178301",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9664c36c-7e00-4ef3-89da-fa62bf85a87c",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e324e289-f807-413e-92e3-a5da897fb105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a variable for the number of epochs we wish to train for\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "875f47ed-dcbd-4d0f-80e7-e74c3d06c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 6s - loss: 0.2529 - accuracy: 0.9242 - val_loss: 0.1206 - val_accuracy: 0.9652 - 6s/epoch - 11ms/step\n",
      "Epoch 2/5\n",
      "540/540 - 4s - loss: 0.0981 - accuracy: 0.9693 - val_loss: 0.0820 - val_accuracy: 0.9748 - 4s/epoch - 7ms/step\n",
      "Epoch 3/5\n",
      "540/540 - 4s - loss: 0.0657 - accuracy: 0.9795 - val_loss: 0.0667 - val_accuracy: 0.9792 - 4s/epoch - 7ms/step\n",
      "Epoch 4/5\n",
      "540/540 - 4s - loss: 0.0475 - accuracy: 0.9848 - val_loss: 0.0452 - val_accuracy: 0.9870 - 4s/epoch - 7ms/step\n",
      "Epoch 5/5\n",
      "540/540 - 3s - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.0461 - val_accuracy: 0.9852 - 3s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a71573b5e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8c18d-ba9c-4996-ad95-4c49b21e4390",
   "metadata": {},
   "source": [
    "**Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53004598-e7b5-4a13-b390-a1730b9eb1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 740ms/step - loss: 0.0694 - accuracy: 0.9772\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "322a4962-c8eb-4943-a794-c1599f03c0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07. Test accuracy: 97.72%\n"
     ]
    }
   ],
   "source": [
    "# We can apply some nice formatting if we want to\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79846678-3cf1-41ea-8492-9eb6a48d8fe2",
   "metadata": {},
   "source": [
    "**Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adcaa4db-5911-4328-9cf9-786e44912a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnist_model.h5\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbe5d7-3b91-49a9-a023-0b3610b8fef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ef13e-44fc-4d39-8527-0af6f8195669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:udemycourse]",
   "language": "python",
   "name": "conda-env-udemycourse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
